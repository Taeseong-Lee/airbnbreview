import pandas as pd
import networkx as nx
from sklearn.feature_extraction.text import CountVectorizer

# í´ëŸ¬ìŠ¤í„° 1 ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv("airbnbview/cluster_0_reviews.csv")
texts = df['content'].dropna().astype(str).tolist()

# 1. 2-gram ë²¡í„°ë¼ì´ì €
vectorizer = CountVectorizer(ngram_range=(2,2), stop_words='english')
X = vectorizer.fit_transform(texts)

# 2. ë‹¨ì–´ìŒ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
terms = vectorizer.get_feature_names_out()
co_occur_matrix = X.T @ X
co_occur_matrix.setdiag(0)

# 3. ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ìƒì„±
G = nx.from_scipy_sparse_array(co_occur_matrix)

# 4. ì¤‘ì‹¬ì„± ê³„ì‚°
centrality = nx.degree_centrality(G)
top_keywords = sorted(centrality.items(), key=lambda x: x[1], reverse=True)[:15]

# 5. ê²°ê³¼ ì¶œë ¥
print("ğŸ”‘ Top 15 Central Terms in Cluster 0:")
for term, score in top_keywords:
    print(f"{terms[term]}: {score:.4f}")
